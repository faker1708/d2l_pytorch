{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caf5f90e",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 模型选择、欠拟合和过拟合\n",
    ":label:`sec_model_selection`\n",
    "\n",
    "作为机器学习科学家，我们的目标是发现*模式*（pattern）。\n",
    "但是，我们如何才能确定模型是真正发现了一种泛化的模式，\n",
    "而不是简单地记住了数据呢？\n",
    "例如，我们想要在患者的基因数据与痴呆状态之间寻找模式，\n",
    "其中标签是从集合$\\{\\text{痴呆}, \\text{轻度认知障碍}, \\text{健康}\\}$中提取的。\n",
    "因为基因可以唯一确定每个个体（不考虑双胞胎），\n",
    "所以在这个任务中是有可能记住整个数据集的。\n",
    "\n",
    "我们不想让模型只会做这样的事情：“那是鲍勃！我记得他！他有痴呆症！”。\n",
    "原因很简单：当我们将来部署该模型时，模型需要判断从未见过的患者。\n",
    "只有当模型真正发现了一种泛化模式时，才会作出有效的预测。\n",
    "\n",
    "更正式地说，我们的目标是发现某些模式，\n",
    "这些模式捕捉到了我们训练集潜在总体的规律。\n",
    "如果成功做到了这点，即使是对以前从未遇到过的个体，\n",
    "模型也可以成功地评估风险。\n",
    "如何发现可以泛化的模式是机器学习的根本问题。\n",
    "\n",
    "困难在于，当我们训练模型时，我们只能访问数据中的小部分样本。\n",
    "最大的公开图像数据集包含大约一百万张图像。\n",
    "而在大部分时候，我们只能从数千或数万个数据样本中学习。\n",
    "在大型医院系统中，我们可能会访问数十万份医疗记录。\n",
    "当我们使用有限的样本时，可能会遇到这样的问题：\n",
    "当收集到更多的数据时，会发现之前找到的明显关系并不成立。\n",
    "\n",
    "将模型在训练数据上拟合的比在潜在分布中更接近的现象称为*过拟合*（overfitting），\n",
    "用于对抗过拟合的技术称为*正则化*（regularization）。\n",
    "在前面的章节中，有些读者可能在用Fashion-MNIST数据集做实验时已经观察到了这种过拟合现象。\n",
    "在实验中调整模型架构或超参数时会发现：\n",
    "如果有足够多的神经元、层数和训练迭代周期，\n",
    "模型最终可以在训练集上达到完美的精度，此时测试集的准确性却下降了。\n",
    "\n",
    "## 训练误差和泛化误差\n",
    "\n",
    "为了进一步讨论这一现象，我们需要了解训练误差和泛化误差。\n",
    "*训练误差*（training error）是指，\n",
    "模型在训练数据集上计算得到的误差。\n",
    "*泛化误差*（generalization error）是指，\n",
    "模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。\n",
    "\n",
    "问题是，我们永远不能准确地计算出泛化误差。\n",
    "这是因为无限多的数据样本是一个虚构的对象。\n",
    "在实际中，我们只能通过将模型应用于一个独立的测试集来估计泛化误差，\n",
    "该测试集由随机选取的、未曾在训练集中出现的数据样本构成。\n",
    "\n",
    "下面的三个思维实验将有助于更好地说明这种情况。\n",
    "假设一个大学生正在努力准备期末考试。\n",
    "一个勤奋的学生会努力做好练习，并利用往年的考试题目来测试自己的能力。\n",
    "尽管如此，在过去的考试题目上取得好成绩并不能保证他会在真正考试时发挥出色。\n",
    "例如，学生可能试图通过死记硬背考题的答案来做准备。\n",
    "他甚至可以完全记住过去考试的答案。\n",
    "另一名学生可能会通过试图理解给出某些答案的原因来做准备。\n",
    "在大多数情况下，后者会考得更好。\n",
    "\n",
    "类似地，考虑一个简单地使用查表法来回答问题的模型。\n",
    "如果允许的输入集合是离散的并且相当小，\n",
    "那么也许在查看许多训练样本后，该方法将执行得很好。\n",
    "但当这个模型面对从未见过的例子时，它表现的可能比随机猜测好不到哪去。\n",
    "这是因为输入空间太大了，远远不可能记住每一个可能的输入所对应的答案。\n",
    "例如，考虑$28\\times28$的灰度图像。\n",
    "如果每个像素可以取$256$个灰度值中的一个，\n",
    "则有$256^{784}$个可能的图像。\n",
    "这意味着指甲大小的低分辨率灰度图像的数量比宇宙中的原子要多得多。\n",
    "即使我们可能遇到这样的数据，我们也不可能存储整个查找表。\n",
    "\n",
    "最后，考虑对掷硬币的结果（类别0：正面，类别1：反面）进行分类的问题。\n",
    "假设硬币是公平的，无论我们想出什么算法，泛化误差始终是$\\frac{1}{2}$。\n",
    "然而，对于大多数算法，我们应该期望训练误差会更低（取决于运气）。\n",
    "考虑数据集{0，1，1，1，0，1}。\n",
    "我们的算法不需要额外的特征，将倾向于总是预测*多数类*，\n",
    "从我们有限的样本来看，它似乎是1占主流。\n",
    "在这种情况下，总是预测类1的模型将产生$\\frac{1}{3}$的误差，\n",
    "这比我们的泛化误差要好得多。\n",
    "当我们逐渐增加数据量，正面比例明显偏离$\\frac{1}{2}$的可能性将会降低，\n",
    "我们的训练误差将与泛化误差相匹配。\n",
    "\n",
    "### 统计学习理论\n",
    "\n",
    "由于泛化是机器学习中的基本问题，\n",
    "许多数学家和理论家毕生致力于研究描述这一现象的形式理论。\n",
    "在[同名定理（eponymous theorem）](https://en.wikipedia.org/wiki/Glivenko%E2%80%93Cantelli_theorem)中，\n",
    "格里文科和坎特利推导出了训练误差收敛到泛化误差的速率。\n",
    "在一系列开创性的论文中，\n",
    "[Vapnik和Chervonenkis](https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory)\n",
    "将这一理论扩展到更一般种类的函数。\n",
    "这项工作为统计学习理论奠定了基础。\n",
    "\n",
    "在我们目前已探讨、并将在之后继续探讨的监督学习情景中，\n",
    "我们假设训练数据和测试数据都是从相同的分布中独立提取的。\n",
    "这通常被称为*独立同分布假设*（i.i.d. assumption），\n",
    "这意味着对数据进行采样的过程没有进行“记忆”。\n",
    "换句话说，抽取的第2个样本和第3个样本的相关性，\n",
    "并不比抽取的第2个样本和第200万个样本的相关性更强。\n",
    "\n",
    "要成为一名优秀的机器学习科学家需要具备批判性思考能力。\n",
    "假设是存在漏洞的，即很容易找出假设失效的情况。\n",
    "如果我们根据从加州大学旧金山分校医学中心的患者数据训练死亡风险预测模型，\n",
    "并将其应用于马萨诸塞州综合医院的患者数据，结果会怎么样？\n",
    "这两个数据的分布可能不完全一样。\n",
    "此外，抽样过程可能与时间有关。\n",
    "比如当我们对微博的主题进行分类时，\n",
    "新闻周期会使得正在讨论的话题产生时间依赖性，从而违反独立性假设。\n",
    "\n",
    "有时候我们即使轻微违背独立同分布假设，模型仍将继续运行得非常好。\n",
    "比如，我们有许多有用的工具已经应用于现实，如人脸识别、语音识别和语言翻译。\n",
    "毕竟，几乎所有现实的应用都至少涉及到一些违背独立同分布假设的情况。\n",
    "\n",
    "有些违背独立同分布假设的行为肯定会带来麻烦。\n",
    "比如，我们试图只用来自大学生的人脸数据来训练一个人脸识别系统，\n",
    "然后想要用它来监测疗养院中的老人。\n",
    "这不太可能有效，因为大学生看起来往往与老年人有很大的不同。\n",
    "\n",
    "在接下来的章节中，我们将讨论因违背独立同分布假设而引起的问题。\n",
    "目前，即使认为独立同分布假设是理所当然的，理解泛化性也是一个困难的问题。\n",
    "此外，能够解释深层神经网络泛化性能的理论基础，\n",
    "也仍在继续困扰着学习理论领域最伟大的学者们。\n",
    "\n",
    "当我们训练模型时，我们试图找到一个能够尽可能拟合训练数据的函数。\n",
    "但是如果它执行地“太好了”，而不能对看不见的数据做到很好泛化，就会导致过拟合。\n",
    "这种情况正是我们想要避免或控制的。\n",
    "深度学习中有许多启发式的技术旨在防止过拟合。\n",
    "\n",
    "### 模型复杂性\n",
    "\n",
    "当我们有简单的模型和大量的数据时，我们期望泛化误差与训练误差相近。\n",
    "当我们有更复杂的模型和更少的样本时，我们预计训练误差会下降，但泛化误差会增大。\n",
    "模型复杂性由什么构成是一个复杂的问题。\n",
    "一个模型是否能很好地泛化取决于很多因素。\n",
    "例如，具有更多参数的模型可能被认为更复杂，\n",
    "参数有更大取值范围的模型可能更为复杂。\n",
    "通常对于神经网络，我们认为需要更多训练迭代的模型比较复杂，\n",
    "而需要*早停*（early stopping）的模型（即较少训练迭代周期）就不那么复杂。\n",
    "\n",
    "我们很难比较本质上不同大类的模型之间（例如，决策树与神经网络）的复杂性。\n",
    "就目前而言，一条简单的经验法则相当有用：\n",
    "统计学家认为，能够轻松解释任意事实的模型是复杂的，\n",
    "而表达能力有限但仍能很好地解释数据的模型可能更有现实用途。\n",
    "在哲学上，这与波普尔的科学理论的可证伪性标准密切相关：\n",
    "如果一个理论能拟合数据，且有具体的测试可以用来证明它是错误的，那么它就是好的。\n",
    "这一点很重要，因为所有的统计估计都是*事后归纳*。\n",
    "也就是说，我们在观察事实之后进行估计，因此容易受到相关谬误的影响。\n",
    "目前，我们将把哲学放在一边，坚持更切实的问题。\n",
    "\n",
    "本节为了给出一些直观的印象，我们将重点介绍几个倾向于影响模型泛化的因素。\n",
    "\n",
    "1. 可调整参数的数量。当可调整参数的数量（有时称为*自由度*）很大时，模型往往更容易过拟合。\n",
    "1. 参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。\n",
    "1. 训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。\n",
    "\n",
    "## 模型选择\n",
    "\n",
    "在机器学习中，我们通常在评估几个候选模型后选择最终的模型。\n",
    "这个过程叫做*模型选择*。\n",
    "有时，需要进行比较的模型在本质上是完全不同的（比如，决策树与线性模型）。\n",
    "又有时，我们需要比较不同的超参数设置下的同一类模型。\n",
    "\n",
    "例如，训练多层感知机模型时，我们可能希望比较具有\n",
    "不同数量的隐藏层、不同数量的隐藏单元以及不同的激活函数组合的模型。\n",
    "为了确定候选模型中的最佳模型，我们通常会使用验证集。\n",
    "\n",
    "### 验证集\n",
    "\n",
    "原则上，在我们确定所有的超参数之前，我们不希望用到测试集。\n",
    "如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险，那就麻烦大了。\n",
    "如果我们过拟合了训练数据，还可以在测试数据上的评估来判断过拟合。\n",
    "但是如果我们过拟合了测试数据，我们又该怎么知道呢？\n",
    "\n",
    "因此，我们决不能依靠测试数据进行模型选择。\n",
    "然而，我们也不能仅仅依靠训练数据来选择模型，因为我们无法估计训练数据的泛化误差。\n",
    "\n",
    "在实际应用中，情况变得更加复杂。\n",
    "虽然理想情况下我们只会使用测试数据一次，\n",
    "以评估最好的模型或比较一些模型效果，但现实是测试数据很少在使用一次后被丢弃。\n",
    "我们很少能有充足的数据来对每一轮实验采用全新测试集。\n",
    "\n",
    "解决此问题的常见做法是将我们的数据分成三份，\n",
    "除了训练和测试数据集之外，还增加一个*验证数据集*（validation dataset），\n",
    "也叫*验证集*（validation set）。\n",
    "但现实是验证数据和测试数据之间的边界模糊得令人担忧。\n",
    "除非另有明确说明，否则在这本书的实验中，\n",
    "我们实际上是在使用应该被正确地称为训练数据和验证数据的数据集，\n",
    "并没有真正的测试数据集。\n",
    "因此，书中每次实验报告的准确度都是验证集准确度，而不是测试集准确度。\n",
    "\n",
    "### $K$折交叉验证\n",
    "\n",
    "当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集。\n",
    "这个问题的一个流行的解决方案是采用$K$*折交叉验证*。\n",
    "这里，原始训练数据被分成$K$个不重叠的子集。\n",
    "然后执行$K$次模型训练和验证，每次在$K-1$个子集上进行训练，\n",
    "并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。\n",
    "最后，通过对$K$次实验的结果取平均来估计训练和验证误差。\n",
    "\n",
    "## 欠拟合还是过拟合？\n",
    "\n",
    "当我们比较训练和验证误差时，我们要注意两种常见的情况。\n",
    "首先，我们要注意这样的情况：训练误差和验证误差都很严重，\n",
    "但它们之间仅有一点差距。\n",
    "如果模型不能降低训练误差，这可能意味着模型过于简单（即表达能力不足），\n",
    "无法捕获试图学习的模式。\n",
    "此外，由于我们的训练和验证误差之间的*泛化误差*很小，\n",
    "我们有理由相信可以用一个更复杂的模型降低训练误差。\n",
    "这种现象被称为*欠拟合*（underfitting）。\n",
    "\n",
    "另一方面，当我们的训练误差明显低于验证误差时要小心，\n",
    "这表明严重的*过拟合*（overfitting）。\n",
    "注意，*过拟合*并不总是一件坏事。\n",
    "特别是在深度学习领域，众所周知，\n",
    "最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。\n",
    "最终，我们通常更关心验证误差，而不是训练误差和验证误差之间的差距。\n",
    "\n",
    "是否过拟合或欠拟合可能取决于模型复杂性和可用训练数据集的大小，\n",
    "这两个点将在下面进行讨论。\n",
    "\n",
    "### 模型复杂性\n",
    "\n",
    "为了说明一些关于过拟合和模型复杂性的经典直觉，\n",
    "我们给出一个多项式的例子。\n",
    "给定由单个特征$x$和对应实数标签$y$组成的训练数据，\n",
    "我们试图找到下面的$d$阶多项式来估计标签$y$。\n",
    "\n",
    "$$\\hat{y}= \\sum_{i=0}^d x^i w_i$$\n",
    "\n",
    "这只是一个线性回归问题，我们的特征是$x$的幂给出的，\n",
    "模型的权重是$w_i$给出的，偏置是$w_0$给出的\n",
    "（因为对于所有的$x$都有$x^0 = 1$）。\n",
    "由于这只是一个线性回归问题，我们可以使用平方误差作为我们的损失函数。\n",
    "\n",
    "高阶多项式函数比低阶多项式函数复杂得多。\n",
    "高阶多项式的参数较多，模型函数的选择范围较广。\n",
    "因此在固定训练数据集的情况下，\n",
    "高阶多项式函数相对于低阶多项式的训练误差应该始终更低（最坏也是相等）。\n",
    "事实上，当数据样本包含了$x$的不同值时，\n",
    "函数阶数等于数据样本数量的多项式函数可以完美拟合训练集。\n",
    "在 :numref:`fig_capacity_vs_error`中，\n",
    "我们直观地描述了多项式的阶数和欠拟合与过拟合之间的关系。\n",
    "\n",
    "\n",
    "![模型复杂度对欠拟合和过拟合的影响](../img/capacity-vs-error.svg)\n",
    ":label:`fig_capacity_vs_error`\n",
    "\n",
    "### 数据集大小\n",
    "\n",
    "另一个重要因素是数据集的大小。\n",
    "训练数据集中的样本越少，我们就越有可能（且更严重地）过拟合。\n",
    "随着训练数据量的增加，泛化误差通常会减小。\n",
    "此外，一般来说，更多的数据不会有什么坏处。\n",
    "对于固定的任务和数据分布，模型复杂性和数据集大小之间通常存在关系。\n",
    "给出更多的数据，我们可能会尝试拟合一个更复杂的模型。\n",
    "能够拟合更复杂的模型可能是有益的。\n",
    "如果没有足够的数据，简单的模型可能更有用。\n",
    "对于许多任务，深度学习只有在有数千个训练样本时才优于线性模型。\n",
    "从一定程度上来说，深度学习目前的生机要归功于\n",
    "廉价存储、互联设备以及数字化经济带来的海量数据集。\n",
    "\n",
    "## 多项式回归\n",
    "\n",
    "我们现在可以(**通过多项式拟合来探索这些概念**)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c36b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:54.120880Z",
     "iopub.status.busy": "2022-12-07T17:01:54.120324Z",
     "iopub.status.idle": "2022-12-07T17:01:56.633520Z",
     "shell.execute_reply": "2022-12-07T17:01:56.632657Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8902acd7",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "### 生成数据集\n",
    "\n",
    "给定$x$，我们将[**使用以下三阶多项式来生成训练和测试数据的标签：**]\n",
    "\n",
    "(**$$y = 5 + 1.2x - 3.4\\frac{x^2}{2!} + 5.6 \\frac{x^3}{3!} + \\epsilon \\text{ where }\n",
    "\\epsilon \\sim \\mathcal{N}(0, 0.1^2).$$**)\n",
    "\n",
    "噪声项$\\epsilon$服从均值为0且标准差为0.1的正态分布。\n",
    "在优化的过程中，我们通常希望避免非常大的梯度值或损失值。\n",
    "这就是我们将特征从$x^i$调整为$\\frac{x^i}{i!}$的原因，\n",
    "这样可以避免很大的$i$带来的特别大的指数值。\n",
    "我们将为训练集和测试集各生成100个样本。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ab17ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:56.637671Z",
     "iopub.status.busy": "2022-12-07T17:01:56.637103Z",
     "iopub.status.idle": "2022-12-07T17:01:56.645127Z",
     "shell.execute_reply": "2022-12-07T17:01:56.644345Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "max_degree = 20  # 多项式的最大阶数\n",
    "n_train, n_test = 100, 100  # 训练和测试数据集大小\n",
    "true_w = np.zeros(max_degree)  # 分配大量的空间\n",
    "true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])\n",
    "\n",
    "features = np.random.normal(size=(n_train + n_test, 1))\n",
    "np.random.shuffle(features)\n",
    "poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))\n",
    "for i in range(max_degree):\n",
    "    poly_features[:, i] /= math.gamma(i + 1)  # gamma(n)=(n-1)!\n",
    "# labels的维度:(n_train+n_test,)\n",
    "labels = np.dot(poly_features, true_w)\n",
    "labels += np.random.normal(scale=0.1, size=labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c4ad2",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "同样，存储在`poly_features`中的单项式由gamma函数重新缩放，\n",
    "其中$\\Gamma(n)=(n-1)!$。\n",
    "从生成的数据集中[**查看一下前2个样本**]，\n",
    "第一个值是与偏置相对应的常量特征。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3be7f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:56.648429Z",
     "iopub.status.busy": "2022-12-07T17:01:56.647994Z",
     "iopub.status.idle": "2022-12-07T17:01:56.669697Z",
     "shell.execute_reply": "2022-12-07T17:01:56.668935Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# NumPy ndarray转换为tensor\n",
    "true_w, features, poly_features, labels = [torch.tensor(x, dtype=\n",
    "    torch.float32) for x in [true_w, features, poly_features, labels]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012dc12f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:56.672992Z",
     "iopub.status.busy": "2022-12-07T17:01:56.672555Z",
     "iopub.status.idle": "2022-12-07T17:01:56.682143Z",
     "shell.execute_reply": "2022-12-07T17:01:56.681334Z"
    },
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5528],\n",
       "         [-1.5194]]),\n",
       " tensor([[ 1.0000e+00,  5.5284e-01,  1.5282e-01,  2.8161e-02,  3.8922e-03,\n",
       "           4.3036e-04,  3.9653e-05,  3.1317e-06,  2.1642e-07,  1.3294e-08,\n",
       "           7.3494e-10,  3.6937e-11,  1.7017e-12,  7.2367e-14,  2.8577e-15,\n",
       "           1.0532e-16,  3.6392e-18,  1.1835e-19,  3.6349e-21,  1.0576e-22],\n",
       "         [ 1.0000e+00, -1.5194e+00,  1.1543e+00, -5.8461e-01,  2.2207e-01,\n",
       "          -6.7481e-02,  1.7089e-02, -3.7092e-03,  7.0447e-04, -1.1893e-04,\n",
       "           1.8070e-05, -2.4960e-06,  3.1604e-07, -3.6938e-08,  4.0088e-09,\n",
       "          -4.0607e-10,  3.8561e-11, -3.4465e-12,  2.9092e-13, -2.3264e-14]]),\n",
       " tensor([ 5.3166, -4.1645]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:2], poly_features[:2, :], labels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70237741",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "### 对模型进行训练和测试\n",
    "\n",
    "首先让我们[**实现一个函数来评估模型在给定数据集上的损失**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cea0962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:56.685564Z",
     "iopub.status.busy": "2022-12-07T17:01:56.685120Z",
     "iopub.status.idle": "2022-12-07T17:01:56.690488Z",
     "shell.execute_reply": "2022-12-07T17:01:56.689729Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate_loss(net, data_iter, loss):  #@save\n",
    "    \"\"\"评估给定数据集上模型的损失\"\"\"\n",
    "    metric = d2l.Accumulator(2)  # 损失的总和,样本数量\n",
    "    for X, y in data_iter:\n",
    "        out = net(X)\n",
    "        y = y.reshape(out.shape)\n",
    "        l = loss(out, y)\n",
    "        metric.add(l.sum(), l.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c488e62f",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "现在[**定义训练函数**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cdb221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:56.693754Z",
     "iopub.status.busy": "2022-12-07T17:01:56.693324Z",
     "iopub.status.idle": "2022-12-07T17:01:56.701367Z",
     "shell.execute_reply": "2022-12-07T17:01:56.700517Z"
    },
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def train(train_features, test_features, train_labels, test_labels,\n",
    "          num_epochs=400):\n",
    "    loss = nn.MSELoss(reduction='none')\n",
    "    input_shape = train_features.shape[-1]\n",
    "    # 不设置偏置，因为我们已经在多项式中实现了它\n",
    "    net = nn.Sequential(nn.Linear(input_shape, 1, bias=False))\n",
    "    batch_size = min(10, train_labels.shape[0])\n",
    "    train_iter = d2l.load_array((train_features, train_labels.reshape(-1,1)),\n",
    "                                batch_size)\n",
    "    test_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)),\n",
    "                               batch_size, is_train=False)\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log',\n",
    "                            xlim=[1, num_epochs], ylim=[1e-3, 1e2],\n",
    "                            legend=['train', 'test'])\n",
    "    for epoch in range(num_epochs):\n",
    "        d2l.train_epoch_ch3(net, train_iter, loss, trainer)\n",
    "        if epoch == 0 or (epoch + 1) % 20 == 0:\n",
    "            animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),\n",
    "                                     evaluate_loss(net, test_iter, loss)))\n",
    "    print('weight:', net[0].weight.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547eeaf",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "### [**三阶多项式函数拟合(正常)**]\n",
    "\n",
    "我们将首先使用三阶多项式函数，它与数据生成函数的阶数相同。\n",
    "结果表明，该模型能有效降低训练损失和测试损失。\n",
    "学习到的模型参数也接近真实值$w = [5, 1.2, -3.4, 5.6]$。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b182c32c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:01:56.704680Z",
     "iopub.status.busy": "2022-12-07T17:01:56.704165Z",
     "iopub.status.idle": "2022-12-07T17:02:09.833316Z",
     "shell.execute_reply": "2022-12-07T17:02:09.832487Z"
    },
    "origin_pos": 20,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# 从多项式特征中选择前4个维度，即1,x,x^2/2!,x^3/3!\n",
    "# train(poly_features[:n_train, :4], poly_features[n_train:, :4],\n",
    "#       labels[:n_train], labels[n_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae479f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:02:09.836970Z",
     "iopub.status.busy": "2022-12-07T17:02:09.836382Z",
     "iopub.status.idle": "2022-12-07T17:02:22.637628Z",
     "shell.execute_reply": "2022-12-07T17:02:22.636774Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# 从多项式特征中选择前2个维度，即1和x\n",
    "# train(poly_features[:n_train, :1], poly_features[n_train:, :2],\n",
    "#       labels[:n_train], labels[n_train:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08393a",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "### [**线性函数拟合(欠拟合)**]\n",
    "\n",
    "让我们再看看线性函数拟合，减少该模型的训练损失相对困难。\n",
    "在最后一个迭代周期完成后，训练损失仍然很高。\n",
    "当用来拟合非线性模式（如这里的三阶多项式函数）时，线性模型容易欠拟合。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba5873f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:02:09.836970Z",
     "iopub.status.busy": "2022-12-07T17:02:09.836382Z",
     "iopub.status.idle": "2022-12-07T17:02:22.637628Z",
     "shell.execute_reply": "2022-12-07T17:02:22.636774Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# 从多项式特征中选择前2个维度，即1和x\n",
    "# train(poly_features[:n_train, :2], poly_features[n_train:, :2],\n",
    "#       labels[:n_train], labels[n_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94cd259d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:02:09.836970Z",
     "iopub.status.busy": "2022-12-07T17:02:09.836382Z",
     "iopub.status.idle": "2022-12-07T17:02:22.637628Z",
     "shell.execute_reply": "2022-12-07T17:02:22.636774Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# # 从多项式特征中选择前2个维度，即1和x\n",
    "# train(poly_features[:n_train, :3], poly_features[n_train:, :2],\n",
    "#       labels[:n_train], labels[n_train:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe337437",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "### [**高阶多项式函数拟合(过拟合)**]\n",
    "\n",
    "现在，让我们尝试使用一个阶数过高的多项式来训练模型。\n",
    "在这种情况下，没有足够的数据用于学到高阶系数应该具有接近于零的值。\n",
    "因此，这个过于复杂的模型会轻易受到训练数据中噪声的影响。\n",
    "虽然训练损失可以有效地降低，但测试损失仍然很高。\n",
    "结果表明，复杂模型对数据造成了过拟合。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d15f78f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T17:02:22.643049Z",
     "iopub.status.busy": "2022-12-07T17:02:22.642410Z",
     "iopub.status.idle": "2022-12-07T17:03:09.022157Z",
     "shell.execute_reply": "2022-12-07T17:03:09.021355Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e20d3de8ba76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 从多项式特征中选取所有维度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m train(poly_features[:n_train, :], poly_features[n_train:, :],\n\u001b[0;32m----> 3\u001b[0;31m       labels[:n_train], labels[n_train:], num_epochs=1500)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-0dd230dad49a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_features, test_features, train_labels, test_labels, num_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m                             legend=['train', 'test'])\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch_ch3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/d2l/torch.py\u001b[0m in \u001b[0;36mtrain_epoch_ch3\u001b[0;34m(net, train_iter, loss, updater)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;31m# Using PyTorch in-built optimizer & loss criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mupdater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0mupdater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"170.777344pt\" version=\"1.1\" viewBox=\"0 0 240.554688 170.777344\" width=\"240.554688pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-03-07T21:21:51.890479</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 170.777344 \n",
       "L 240.554688 170.777344 \n",
       "L 240.554688 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 146.899219 \n",
       "L 225.403125 146.899219 \n",
       "L 225.403125 10.999219 \n",
       "L 30.103125 10.999219 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m4287ecdddc\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4287ecdddc\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(22.151563 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "        <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.163125\" xlink:href=\"#m4287ecdddc\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(61.211563 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.223125\" xlink:href=\"#m4287ecdddc\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(100.271563 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.283125\" xlink:href=\"#m4287ecdddc\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(139.331563 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.343125\" xlink:href=\"#m4287ecdddc\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(178.391563 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"225.403125\" xlink:href=\"#m4287ecdddc\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(217.451563 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m7606dd1f81\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7606dd1f81\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(7.2 150.698437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7606dd1f81\" y=\"119.719219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 123.518437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7606dd1f81\" y=\"92.539219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 96.338437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7606dd1f81\" y=\"65.359219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 69.158437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7606dd1f81\" y=\"38.179219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 41.978437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m7606dd1f81\" y=\"10.999219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 146.899219 \n",
       "L 30.103125 10.999219 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 146.899219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 146.899219 \n",
       "L 225.403125 146.899219 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 10.999219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 从多项式特征中选取所有维度\n",
    "# train(poly_features[:n_train, :], poly_features[n_train:, :],\n",
    "#       labels[:n_train], labels[n_train:], num_epochs=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f5d62",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "在接下来的章节中，我们将继续讨论过拟合问题和处理这些问题的方法，例如权重衰减和dropout。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 欠拟合是指模型无法继续减少训练误差。过拟合是指训练误差远小于验证误差。\n",
    "* 由于不能基于训练误差来估计泛化误差，因此简单地最小化训练误差并不一定意味着泛化误差的减小。机器学习模型需要注意防止过拟合，即防止泛化误差过大。\n",
    "* 验证集可以用于模型选择，但不能过于随意地使用它。\n",
    "* 我们应该选择一个复杂度适当的模型，避免使用数量不足的训练样本。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 这个多项式回归问题可以准确地解出吗？提示：使用线性代数。\n",
    "1. 考虑多项式的模型选择。\n",
    "    1. 绘制训练损失与模型复杂度（多项式的阶数）的关系图。观察到了什么？需要多少阶的多项式才能将训练损失减少到0?\n",
    "    1. 在这种情况下绘制测试的损失图。\n",
    "    1. 生成同样的图，作为数据量的函数。\n",
    "1. 如果不对多项式特征$x^i$进行标准化($1/i!$)，会发生什么事情？能用其他方法解决这个问题吗？\n",
    "1. 泛化误差可能为零吗？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982f3f1",
   "metadata": {
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1806)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cca6b7f3d1f788774e3dfc30beb0c5cfbb80b7f5279eded308c5128b68a421ae"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
